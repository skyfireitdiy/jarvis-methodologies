{
  "problem_type": "防止数据结构无限增长优化",
  "content": "# 防止数据结构无限增长优化\n\n## 问题重述\n\n在长期运行的系统中，某些数据结构会随着时间推移无限增长，导致：\n- 内存占用持续增加\n- 性能逐渐下降（字符串拼接、列表遍历变慢）\n- 系统资源耗尽\n- 提示词/日志/历史记录过长\n\n## 通用解决流程\n\n### 第一步：问题诊断\n\n1. **识别增长的数据结构**\n   - 查找使用 `+=` 或 `append` 的代码\n   - 关注字符串、列表、字典等可变类型\n   - 检查是否有清理/重置机制\n\n2. **定位增长源头**\n   - 搜索关键词：`pin_content`, `history`, `log`, `cache`\n   - 检查循环中的追加操作\n   - 查看是否有条件判断来限制增长\n\n3. **评估影响范围**\n   - 哪些模块/类使用该数据结构\n   - 是否有外部依赖\n   - 改动的风险等级\n\n### 第二步：设计替代方案\n\n**数据结构选择：**\n\n| 当前结构 | 推荐替代 | 适用场景 |\n|---------|---------|---------|\n| 字符串拼接 | 列表 + join | 需要频繁追加 |\n| 无限列表 | 固定长度列表 | 只需要最近N条 |\n| 无限字典 | LRU Cache | 需要键值访问 |\n| 全局变量 | 实例变量 | 需要隔离 |\n\n**限制策略：**\n\n1. **固定数量**：维护最近N条记录（如最近10条）\n```python\n   recent_items = []\n   MAX_SIZE = 10\n   recent_items.append(new_item)\n   if len(recent_items) > MAX_SIZE:\n       recent_items.pop(0)\n```\n\n2. **基于时间**：只保留最近N分钟/小时的记录\n```python\n   from datetime import datetime, timedelta\n   cutoff = datetime.now() - timedelta(hours=1)\n   recent_items = [item for item in all_items if item['timestamp'] > cutoff]\n```\n\n3. **基于条件**：根据优先级、重要性筛选\n\n### 第三步：实现迁移方案\n\n**策略A：双轨运行（推荐用于高风险改动）**\n1. 保留原数据结构（向后兼容）\n2. 同时维护新数据结构\n3. 逐步迁移使用方到新结构\n4. 验证稳定后移除旧结构\n\n**策略B：一次性迁移（推荐用于低风险改动）**\n1. 直接替换数据结构\n2. 修改所有使用方\n3. 统一测试验证\n4. 保持接口不变\n\n**向后兼容处理：**\n```python\nclass Agent:\n    def __init__(self):\n        self.pin_content = \"\"  # 保留原属性，不再使用\n        self.recent_memories = []  # 新的数据结构\n```\n\n### 第四步：验证与测试\n\n1. **功能验证**\n   - 新数据结构是否正确维护\n   - 是否正确限制大小\n   - 是否正确展示内容\n\n2. **性能验证**\n   - 内存占用是否降低\n   - 运行时间是否改善\n\n3. **兼容性验证**\n   - 外部调用是否正常\n   - 序列化/反序列化是否正常\n   - 会话恢复是否正常\n\n## 注意事项\n\n### 设计原则\n1. **优先选择简单方案**：固定长度列表最简单，优先考虑\n2. **考虑并发安全**：多线程环境下需要加锁\n3. **避免过早优化**：只有确认存在性能问题才优化\n\n### 实现细节\n1. **使用标准库**：\n   - `collections.deque` - 高效的双端队列，支持 `maxlen`\n   - `collections.OrderedDict` - 实现 LRU Cache\n   - `functools.lru_cache` - 装饰器形式的缓存\n\n2. **边界处理**：\n   - 空列表/队列的访问\n   - 不足N条时的处理\n   - 并发访问的原子性\n\n3. **日志记录**：\n   - 记录数据结构大小变化\n   - 记录清理操作\n   - 便于监控和调试\n\n## 可选步骤\n\n### 高级优化\n\n1. **动态调整限制**：根据系统负载自动调整最大数量\n2. **分级存储**：热数据在内存，冷数据持久化\n3. **压缩存储**：对历史数据进行压缩\n4. **索引优化**：为频繁查询的字段建立索引\n\n## 常见场景示例\n\n### 场景1：聊天记录管理\n```python\n# 问题：chat_history 列表无限增长\nchat_history = []\n\n# 解决方案：使用 deque 限制大小\nfrom collections import deque\nchat_history = deque(maxlen=100)  # 只保留最近100条\n```\n\n### 场景2：日志管理\n```python\n# 问题：log_content 字符串无限增长\nlog_content += new_log + \"\\n\"\n\n# 解决方案：使用列表 + 定期清理\nlogs = []\nMAX_LOGS = 1000\nlogs.append(new_log)\nif len(logs) > MAX_LOGS:\n    logs.pop(0)\nlog_content = \"\\n\".join(logs)\n```\n\n### 场景3：缓存管理\n```python\n# 问题：cache 字典无限增长\ncache = {}\ncache[key] = value\n\n# 解决方案：使用 LRU Cache\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef expensive_function(key):\n    return compute(key)\n```\n\n## 验收标准\n\n- [ ] 数据结构大小得到有效限制\n- [ ] 功能正常，无数据丢失\n- [ ] 内存占用明显降低\n- [ ] 向后兼容，不破坏现有功能\n- [ ] 代码清晰，易于维护\n- [ ] 有适当的单元测试",
  "scope": "global"
}